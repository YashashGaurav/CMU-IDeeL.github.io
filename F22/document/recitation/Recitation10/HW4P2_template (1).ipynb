{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Bootcamp/Recitation for HW4P2\n",
    "## Introduction to LAS (Listen, Attend and Spell)\n",
    "LAS is based on the seq2seq learning framework with attention. The network learns to transcribe an audio sequence signal to a word sequence, one character at a time. It consists of an encoder RNN, which is named the listener, and a decoder RNN, which is named the speller. \n",
    "\n",
    "The listener is a pyramidal RNN that converts low level speech signals into higher level features. The speller is an RNN that converts these higher level features into output utterances by specifying a probability distribution over sequences of characters using the attention mechanism. The listener and the speller are trained jointly.\n",
    "\n",
    "Why called LAS?\n",
    "- (1) Listener (L)\n",
    "- (2) Attention (A)\n",
    "- (3) Speller (S)\n",
    "\n",
    "### Listener\n",
    "See visualizations and more details in the Bootcamp/Recitation video\n",
    "\n",
    "### Attention\n",
    "See visualizations and more details in the Bootcamp/Recitation video\n",
    "\n",
    "### Speller\n",
    "See visualizations and more details in the Bootcamp/Recitation video\n",
    "\n",
    "Some simple rules for the Bootcamp/Recitation today:\n",
    "\n",
    "- (1) This homework is challenging, so I need your cooperation. I will check your understanding frequently. Please type 1 on the chat if you have understood it, 0 otherwise. I need your very honest responses. These feedback will help make the decision if I need to adjust my pace and cover more details. \n",
    "- (2) Please try not to intrepret me, but feel free to type your questions on the chat. After each important concept, I will stop for a while and answer the questions on the chat and give a short QA session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "id": "HTGPr98x0yjO"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-f795a9bde53f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "@Author: Eason\n",
    "@Last Edit: 2021/03/28\n",
    "'''\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils as utils\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random\n",
    "from torch.utils import data\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "print(cuda, sys.version)\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "np.random.seed(5111785)\n",
    "torch.manual_seed(5111785)\n",
    "\n",
    "LETTER_LIST = ['<sos>', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', \\\n",
    "         'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '-', \"'\", '.', '_', '+', ' ', '<eos>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "id": "ZFmcvE1pkDNi"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LETTER_LIST' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e57ced53f82b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# Create the letter2index and index2letter dictionary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mletter2index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex2letter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_dictionaries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLETTER_LIST\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'LETTER_LIST' is not defined"
     ]
    }
   ],
   "source": [
    "def create_dictionaries(letter_list):\n",
    "    '''\n",
    "    Create dictionaries for letter2index and index2letter transformations\n",
    "    '''\n",
    "    pass\n",
    "    \n",
    "def transform_letter_to_index(raw_transcripts):\n",
    "    '''\n",
    "    Transforms text input to numerical input by converting each letter \n",
    "    to its corresponding index from letter_list\n",
    "\n",
    "    Args:\n",
    "        raw_transcripts: Raw text transcripts with the shape of (N, )\n",
    "    \n",
    "    Return:\n",
    "        transcripts: Converted index-format transcripts. This would be a list with a length of N\n",
    "    '''  \n",
    "    pass\n",
    "    \n",
    "# Create the letter2index and index2letter dictionary\n",
    "letter2index, index2letter = create_dictionaries(LETTER_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aJukRb802lQI"
   },
   "outputs": [],
   "source": [
    "# Load the training, validation and testing data\n",
    "train_data = np.load('train.npy', allow_pickle=True, encoding='bytes')\n",
    "valid_data = np.load('dev.npy', allow_pickle=True, encoding='bytes')\n",
    "test_data = np.load('test.npy', allow_pickle=True, encoding='bytes')\n",
    "\n",
    "# Load the training, validation raw text transcripts\n",
    "raw_train_transcript = np.load('train_transcripts.npy', allow_pickle=True,encoding='bytes')\n",
    "raw_valid_transcript = np.load('dev_transcripts.npy', allow_pickle=True,encoding='bytes')\n",
    "\n",
    "# TODO: Convert the raw text transcripts into indexes\n",
    "# train_transcript = \n",
    "# valid_transcript = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WhSD0FOXm5Q6"
   },
   "outputs": [],
   "source": [
    "class MyDataset(data.Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # For testing set, return only x\n",
    "        if self.Y == None:\n",
    "            return torch.tensor(self.X[index].astype(np.float32))\n",
    "        # For training and validation set, return x and y\n",
    "        else:\n",
    "            return torch.tensor(self.X[index].astype(np.float32)), torch.tensor(self.Y[index])\n",
    "\n",
    "def collate_train_val(data):\n",
    "    \"\"\"\n",
    "    Return:\n",
    "        pad_x: the padded x (training/validation speech data) \n",
    "        pad_y: the padded y (text labels - transcripts)\n",
    "        x_len: the length of x\n",
    "        y_len: the length of y\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def collate_test(data):\n",
    "    \"\"\"\n",
    "    Return:\n",
    "        pad_x: the padded x (testing speech data) \n",
    "        x_len: the length of x\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 939,
     "status": "ok",
     "timestamp": 1616929240422,
     "user": {
      "displayName": "Miaoqiong HUANG",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQDvRhasxZL_x5W0TkXPeDpkI70YUDmxXNu3lAtg=s64",
      "userId": "16268214381232649647"
     },
     "user_tz": -480
    },
    "id": "OJKdna5VnIJM",
    "outputId": "619dba22-f9ef-4bd0-a4f3-964f94037df8"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-2951b5189539>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-2951b5189539>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    train_dataset =\u001b[0m\n\u001b[1;37m                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Create datasets\n",
    "train_dataset = \n",
    "valid_dataset = \n",
    "test_dataset = \n",
    "\n",
    "# Create data loaders\n",
    "train_loader = \n",
    "valid_loader = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 807,
     "status": "ok",
     "timestamp": 1616932869762,
     "user": {
      "displayName": "Miaoqiong HUANG",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQDvRhasxZL_x5W0TkXPeDpkI70YUDmxXNu3lAtg=s64",
      "userId": "16268214381232649647"
     },
     "user_tz": -480
    },
    "id": "EfpIMUDzCvT3"
   },
   "outputs": [],
   "source": [
    "class pBLSTM(nn.Module):\n",
    "    '''\n",
    "    Pyramidal BiLSTM\n",
    "    Read paper and understand the concepts and then write your implementation here.\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(pBLSTM, self).__init__()\n",
    "        self.blstm = nn.LSTM(input_size=input_dim, hidden_size=hidden_dim, num_layers=1, bidirectional=True, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 1103,
     "status": "ok",
     "timestamp": 1616934368638,
     "user": {
      "displayName": "Miaoqiong HUANG",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQDvRhasxZL_x5W0TkXPeDpkI70YUDmxXNu3lAtg=s64",
      "userId": "16268214381232649647"
     },
     "user_tz": -480
    },
    "id": "-F9zAQR95P55"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    '''\n",
    "    Encoder takes the utterances as inputs and returns the key, value and unpacked_x_len.\n",
    "    Key and value are linear projections of the output from pBLSTM network for the laster.\n",
    "    '''\n",
    "    def __init__(self, input_dim, encoder_hidden_dim, key_value_size=128):\n",
    "        super(Encoder, self).__init__()\n",
    "        # The first LSTM at the very bottom\n",
    "        self.lstm = nn.LSTM(input_size=input_dim, hidden_size=encoder_hidden_dim, num_layers=1, bidirectional=True, batch_first=True)\n",
    "\n",
    "\n",
    "        # TODO: Define the blocks of pBLSTMs\n",
    "        # ...\n",
    "         \n",
    "        # The linear transformation for producing Key and Value for attention\n",
    "        # Since you are using bidirectional LSTM, be careful about the size of hidden dimension\n",
    "        self.key_network = \n",
    "        self.value_network =\n",
    "\n",
    "    def forward(self, x, x_len):\n",
    "        # Pass through the first LSTM at the very bottom\n",
    "        packed_sequence = rnn_utils.pack_padded_sequence(x, x_len, enforce_sorted=False, batch_first=True) \n",
    "        packed_out, _ = self.lstm(packed_sequence)\n",
    "        \n",
    "\n",
    "        # TODO: Pass through the pBLSTM blocks\n",
    "        # ...\n",
    "        \n",
    "        # Unpack the sequence and get the Key and Value for attention\n",
    "        \n",
    "        # return key, value, unpacked_x_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 752,
     "status": "ok",
     "timestamp": 1616934369093,
     "user": {
      "displayName": "Miaoqiong HUANG",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQDvRhasxZL_x5W0TkXPeDpkI70YUDmxXNu3lAtg=s64",
      "userId": "16268214381232649647"
     },
     "user_tz": -480
    },
    "id": "pqu-MUM8TjUO"
   },
   "outputs": [],
   "source": [
    "def plot_attention(attention):\n",
    "    plt.clf()\n",
    "    sns.heatmap(attention, cmap='GnBu')\n",
    "    plt.show()\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    '''\n",
    "    Attention is calculated using key, value and query from Encoder and decoder.\n",
    "    Below are the set of operations you need to perform for computing attention:\n",
    "        energy = bmm(key, query)\n",
    "        attention = softmax(energy)\n",
    "        context = bmm(attention, value)\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(Attention, self).__init__()\n",
    "\n",
    "    def forward(self, query, key, value, mask):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 1418,
     "status": "ok",
     "timestamp": 1616934372263,
     "user": {
      "displayName": "Miaoqiong HUANG",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQDvRhasxZL_x5W0TkXPeDpkI70YUDmxXNu3lAtg=s64",
      "userId": "16268214381232649647"
     },
     "user_tz": -480
    },
    "id": "zcTC4cK95TYT"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    '''\n",
    "    As mentioned in a previous recitation, each forward call of decoder deals with just one time step.\n",
    "    Thus we use LSTMCell instead of LSTM here.\n",
    "    The output from the seond LSTMCell can be used as query for calculating attention.\n",
    "    In place of value that we get from the attention, this can be replace by context we get from the attention.\n",
    "    Methods like Gumble noise and teacher forcing can also be incorporated for improving the performance.\n",
    "    '''\n",
    "    def __init__(self, vocab_size, decoder_hidden_dim, embed_dim, key_value_size=128):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=letter2index['<eos>'])\n",
    "        self.lstm1 = nn.LSTMCell(input_size=embed_dim + key_value_size, hidden_size=decoder_hidden_dim)\n",
    "        self.lstm2 = nn.LSTMCell(input_size=decoder_hidden_dim, hidden_size=key_value_size)\n",
    "      \n",
    "        self.attention = Attention()     \n",
    "        self.vocab_size = vocab_size\n",
    "        self.character_prob = nn.Linear(2 * key_value_size, vocab_size)\n",
    "        self.key_value_size = key_value_size\n",
    "\n",
    "    def forward(self, key, value, encoder_len, y=None, mode='train'):\n",
    "        '''\n",
    "        Args:\n",
    "            key :(B, T, key_value_size) - Output of the Encoder Key projection layer\n",
    "            value: (B, T, key_value_size) - Output of the Encoder Value projection layer\n",
    "            y: (T, text_len) - Batch input of text with text_length\n",
    "            mode: Train or eval mode\n",
    "        Return:\n",
    "            predictions: the character perdiction probability \n",
    "        '''\n",
    "\n",
    "        B, key_seq_max_len, key_value_size = key.shape\n",
    "\n",
    "\n",
    "        if mode == 'train':\n",
    "            max_len =  y.shape[1]\n",
    "            char_embeddings = self.embedding(y)\n",
    "        else:\n",
    "            max_len = 600\n",
    "\n",
    "        # TODO: Create the attention mask here (outside the for loop rather than inside) to aviod repetition\n",
    "        # ...\n",
    "        \n",
    "        predictions = []\n",
    "        prediction = torch.zeros(B, 1).to(device)\n",
    "        hidden_states = [None, None] \n",
    "        \n",
    "        # TODO: Initialize the context. Be careful here\n",
    "        # context = \n",
    "        \n",
    "        for i in range(max_len):\n",
    "            if mode == 'train':\n",
    "                # TODO: Implement (1) Teacher Forcing and (2) Gumble Noise techniques here\n",
    "                # ...\n",
    "                char_embed = self.embedding(prediction.argmax(dim=-1))\n",
    "            else:\n",
    "                char_embed = self.embedding(prediction.argmax(dim=-1))\n",
    "\n",
    "            y_context = torch.cat([char_embed, context], dim=1)\n",
    "            hidden_states[0] = self.lstm1(y_context, hidden_states[0])\n",
    "\n",
    "            lstm1_hidden = hidden_states[0][0]\n",
    "            hidden_states[1] = self.lstm2(lstm1_hidden, hidden_states[1])\n",
    "            output = hidden_states[1][0]\n",
    "            \n",
    "            # TODO: Compute attention from the output of the second LSTM Cell\n",
    "            # ...\n",
    "            \n",
    "            output_context = torch.cat([output, context], dim=1)\n",
    "            prediction = self.character_prob(output_context)\n",
    "            predictions.append(prediction.unsqueeze(1))\n",
    "        return torch.cat(predictions, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 736,
     "status": "ok",
     "timestamp": 1616934375143,
     "user": {
      "displayName": "Miaoqiong HUANG",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQDvRhasxZL_x5W0TkXPeDpkI70YUDmxXNu3lAtg=s64",
      "userId": "16268214381232649647"
     },
     "user_tz": -480
    },
    "id": "d35FEZhz5Uhx"
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    '''\n",
    "    We train an end-to-end sequence to sequence model comprising of Encoder and Decoder.\n",
    "    This is simply a wrapper \"model\" for your encoder and decoder.\n",
    "    '''\n",
    "    def __init__(self, input_dim, vocab_size, encoder_hidden_dim, decoder_hidden_dim, embed_dim, key_value_size=128):\n",
    "        super(Seq2Seq,self).__init__()\n",
    "        self.encoder = Encoder(input_dim, encoder_hidden_dim, key_value_size=key_value_size)\n",
    "        self.decoder = Decoder(vocab_size, decoder_hidden_dim, embed_dim, key_value_size=key_value_size)\n",
    "\n",
    "    def forward(self, x, x_len, y=None, mode='train'):\n",
    "        key, value, encoder_len = self.encoder(x, x_len)\n",
    "        predictions = self.decoder(key, value, encoder_len, y=y, mode=mode)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "executionInfo": {
     "elapsed": 740,
     "status": "ok",
     "timestamp": 1616934381001,
     "user": {
      "displayName": "Miaoqiong HUANG",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQDvRhasxZL_x5W0TkXPeDpkI70YUDmxXNu3lAtg=s64",
      "userId": "16268214381232649647"
     },
     "user_tz": -480
    },
    "id": "jzpCjd9R5VYV"
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-3-143b1ac22a6b>, line 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-143b1ac22a6b>\"\u001b[1;36m, line \u001b[1;32m23\u001b[0m\n\u001b[1;33m    10) Use torch.nn.utils.clip_grad_norm(model.parameters(), 2)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "def train(model, train_loader, criterion, optimizer, mode):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    \n",
    "    # 0) Iterate through your data loader\n",
    "        # 1) Set the inputs to the device.\n",
    "\n",
    "        # 2) Pass your inputs, and length of speech into the model.\n",
    "\n",
    "        # 3) Generate a mask based on the lengths of the text\n",
    "        #    Ensure the mask is on the device and is the correct shape.   \n",
    "        \n",
    "        # 4. Calculate the loss and mask it to remove the padding part\n",
    "        \n",
    "        # 5. Backward on the masked loss\n",
    "        \n",
    "        # 6. Optional: Use torch.nn.utils.clip_grad_norm(model.parameters(), 2) to clip the gradie\n",
    "\n",
    "        # 7. Take a step with your optimizer\n",
    "        \n",
    "        # 8. print the statistic (loss, edit distance and etc.) for analysis\n",
    "        \n",
    "def val(model, valid_loader):\n",
    "    model.eval()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 6504,
     "status": "ok",
     "timestamp": 1616934407162,
     "user": {
      "displayName": "Miaoqiong HUANG",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQDvRhasxZL_x5W0TkXPeDpkI70YUDmxXNu3lAtg=s64",
      "userId": "16268214381232649647"
     },
     "user_tz": -480
    },
    "id": "PtnTI-s8q4ls",
    "outputId": "acd53df2-b69c-452e-ec59-5b26e552b5c9"
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-4-eaa634bc5b73>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-4-eaa634bc5b73>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    optimizer = optim.Adam(model.parameters(), lr=0.001)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# TODO: Define your model and put it on the device here\n",
    "# ...\n",
    "\n",
    "n_epochs = 25\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss(reduction='none')\n",
    "mode = 'train'\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train(model, train_loader, criterion, optimizer, mode)\n",
    "    val(model, valid_loader)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "HW4P2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
