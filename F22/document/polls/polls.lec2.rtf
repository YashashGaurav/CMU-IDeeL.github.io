{\rtf1\ansi\ansicpg1252\cocoartf2577
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica-Bold;\f1\froman\fcharset0 TimesNewRomanPS-BoldMT;\f2\fswiss\fcharset0 Helvetica;
\f3\ftech\fcharset77 Symbol;}
{\colortbl;\red255\green255\blue255;\red192\green0\blue0;\red51\green51\blue255;}
{\*\expandedcolortbl;;\csgenericrgb\c75294\c0\c0;\csgenericrgb\c20000\c20000\c100000;}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat0\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid1}
{\list\listtemplateid2\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}.}{\leveltext\leveltemplateid101\'02\'00.;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid2}
{\list\listtemplateid3\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat0\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid201\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid3}
{\list\listtemplateid4\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat0\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid301\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid4}
{\list\listtemplateid5\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat0\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid401\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid5}
{\list\listtemplateid6\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}.}{\leveltext\leveltemplateid501\'02\'00.;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid6}
{\list\listtemplateid7\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid601\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid7}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}{\listoverride\listid2\listoverridecount0\ls2}{\listoverride\listid3\listoverridecount0\ls3}{\listoverride\listid4\listoverridecount0\ls4}{\listoverride\listid5\listoverridecount0\ls5}{\listoverride\listid6\listoverridecount0\ls6}{\listoverride\listid7\listoverridecount0\ls7}}
{\info
{\author Bhiksha Raj}}\margl1440\margr1440\vieww12240\viewh15840\viewkind1
\deftab720
\pard\pardeftab720\ri0\sl259\slmult1\sa160\qc\partightenfactor0

\f0\b\fs22 \cf2 Lecture 2 Polls\
\pard\pardeftab720\ri0\sl259\slmult1\sa160\partightenfactor0
\cf2 Slide 10:
\f1 \
\pard\pardeftab720\ri0\sl276\slmult1\sa200\partightenfactor0

\f2\b0 \cf0 1.  Mark all true statements\
\pard\pardeftab720\li720\fi-360\ri0\sl276\slmult1\sa200\partightenfactor0
\ls1\ilvl0
\f3 \cf0 \'a5	
\f2 3x + 7y is a linear combination of x and y \
\ls1\ilvl0
\f3 \'a5	
\f2 3x + 7y + 4 is a linear combination of x and y\
\ls1\ilvl0
\f3 \'a5	
\f2 3x + 7y is an affine function of x and y \
\ls1\ilvl0
\f3 \'a5	
\f2 3x + 7y + 4 is an affine function of x and y 
\f0\b \cf3 \
\pard\pardeftab720\ri0\sl276\slmult1\sa200\partightenfactor0

\f2\b0 \cf0 \
\pard\pardeftab720\ri0\sl276\slmult1\sa200\partightenfactor0

\f0\b \cf2 Slide 50:\
\pard\tx360\pardeftab720\li360\fi-360\ri0\sl276\slmult1\sa200\partightenfactor0
\ls2\ilvl0
\f2\b0 \cf0 1.	How many neurons will be required in the hidden layer of a one-hidden-layer network that models a Boolean function over 10 inputs, where the output for two input bit patterns that differ in only one bit is always different? (I.e. the checkerboard Karnaugh map)\
\pard\pardeftab720\li720\fi-360\ri0\sl276\slmult1\sa200\partightenfactor0
\ls3\ilvl0
\f3 \cf0 \'a5	
\f2 20\
\ls3\ilvl0
\f3 \'a5	
\f2 256\
\ls3\ilvl0
\f3 \'a5	
\f2 512 
\f0\b \cf3 \
\ls3\ilvl0
\f3\b0 \cf0 \'a5	
\f2 1024\
\pard\pardeftab720\ri0\sl276\slmult1\sa200\partightenfactor0
\cf0 \
\pard\pardeftab720\ri0\sl276\slmult1\sa200\partightenfactor0

\f0\b \cf2 Slide 79:\
\pard\pardeftab720\ri0\sl276\slmult1\sa200\partightenfactor0

\f2\b0 \cf0 1.  An XOR network needs two hidden neurons and one output neuron, because we need one hidden neuron for each of the two boundaries of the XOR region, and an output neuron to AND them.  True or false?\
\pard\pardeftab720\li720\fi-360\ri0\sl276\slmult1\sa200\partightenfactor0
\ls4\ilvl0
\f3 \cf0 \'a5	
\f2 True \
\ls4\ilvl0
\f3 \'a5	
\f2 False\
\pard\pardeftab720\ri0\sl276\slmult1\sa200\partightenfactor0
\cf0 \
\pard\pardeftab720\ri0\sl276\slmult1\sa200\partightenfactor0

\f0\b \cf2 Slide 121:\
\pard\pardeftab720\ri0\sl276\slmult1\sa200\partightenfactor0

\f2\b0 \cf0 1. Any real valued function can be modelled exactly by a one-hidden layer network with infinite neurons in the hidden layer, true or false?\
\pard\pardeftab720\li720\fi-360\ri0\sl276\slmult1\sa200\partightenfactor0
\ls5\ilvl0
\f3 \cf0 \'a5	
\f2 False \
\ls5\ilvl0
\f3 \'a5	
\f2 True\
\pard\pardeftab720\ri0\sl276\slmult1\sa200\partightenfactor0
\cf0 Explanation: (it can only be approximated)\
\
\pard\pardeftab720\ri0\sl276\slmult1\sa200\partightenfactor0

\f0\b \cf2 Slide 138:\
\pard\pardeftab720\li360\fi-360\ri0\sl276\slmult1\sa200\partightenfactor0
\ls6\ilvl0
\f2\b0 \cf0 1.	Mark all true statements\
\pard\pardeftab720\li720\fi-360\ri0\sl276\slmult1\sa200\partightenfactor0
\ls7\ilvl0
\f3 \cf0 \'a5	
\f2 A network with an upper bound on layer width (no. of neurons in a layer) can nevertheless model any function by making it sufficiently deep.\
\ls7\ilvl0
\f3 \'a5	
\f2 Networks with "graded" activation functions are more able to compensate for insufficient width through depth, than those with threshold or saturating activations. \cf3 \
\ls7\ilvl0
\f3 \cf0 \'a5	
\f2 We can always compensate for limits in the width and depth of the network by using more graded activations.\
\ls7\ilvl0
\f3 \'a5	
\f2 For a given accuracy of modelling a function, networks with more graded activations will generally be smaller than those with less graded (i.e saturating or thresholding) activations. \cf3 \
}