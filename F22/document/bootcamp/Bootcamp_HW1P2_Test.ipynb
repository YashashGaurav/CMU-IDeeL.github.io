{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data is: [[ 1  2  3]\n",
      " [ 9  5  7]\n",
      " [ 9  4  2]\n",
      " [11  5  7]\n",
      " [11  1 15]\n",
      " [ 0  4 20]\n",
      " [ 2  3  9]\n",
      " [12 18  5]\n",
      " [ 0  6  1]\n",
      " [ 1  1  5]]\n",
      "Shape of training data: (10, 3)\n",
      "********************\n",
      "Training data label is:  [0 1 1 0 1 0 0 1 0 1]\n",
      "Shape of training data labels: (10,)\n",
      "********************\n",
      "********************\n",
      "Shape of Validation data: (4, 3)\n",
      "Shape of validation data labels (4,)\n"
     ]
    }
   ],
   "source": [
    "### Load Data\n",
    "\n",
    "### Training\n",
    "\n",
    "# Training data\n",
    "x_train = np.array([np.array([1,2,3]),np.array([9,5,7]),np.array([9,4,2]),np.array([11,5,7]), np.array([11,1,15]), np.array([0,4,20]),np.array([2,3,9]),np.array([12,18,5]), np.array([0,6,1]), np.array([1,1,5])])\n",
    "print(\"Training data is:\", x_train)\n",
    "print(\"Shape of training data:\", x_train.shape)\n",
    "print(\"*\"*20)\n",
    "# Training labels\n",
    "labels_train = np.asarray([0,1,1,0,1,0,0,1,0,1])\n",
    "print(\"Training data label is: \", labels_train)\n",
    "print(\"Shape of training data labels:\", labels_train.shape)\n",
    "print(\"*\"*20)\n",
    "print(\"*\"*20)\n",
    "### Validation\n",
    "\n",
    "# Validation data\n",
    "x_val = np.array([np.array([4,0,0]),np.array([0,3,9]),np.array([7,7,2]),np.array([1,3,3])])\n",
    "print(\"Shape of Validation data:\", x_val.shape)\n",
    "# Validation labels\n",
    "labels_val = np.asarray([0,1,1,0])\n",
    "print(\"Shape of validation data labels\", labels_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda = False with num_workers = 0\n"
     ]
    }
   ],
   "source": [
    "# Check if cuda is available\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "num_workers = 8 if cuda else 0\n",
    "print(\"Cuda = \"+str(cuda)+\" with num_workers = \"+str(num_workers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset definition\n",
    "\n",
    "class MLPDataset(Dataset):\n",
    "    \n",
    "    # load the dataset\n",
    "    def __init__(self, x, y):\n",
    "        \n",
    "        # store the inputs and outputs\n",
    "        self.X = x\n",
    "        self.y = y\n",
    "        \n",
    "    # number of rows in the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    " \n",
    "    # get a row at an index\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        x = torch.Tensor(self.X[index]).float() \n",
    "        y = self.y[index]\n",
    "    \n",
    "        return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataloaders\n",
    "\n",
    "# Training dataloader\n",
    "train_data = MLPDataset(x_train, labels_train)\n",
    "train_args = dict(shuffle = True, batch_size = 2, drop_last=True)\n",
    "train_loader = DataLoader(train_data, **train_args)\n",
    "\n",
    "# Validation dataloader\n",
    "val_data = MLPDataset(x_val, labels_val)\n",
    "val_args = dict(shuffle = True, batch_size = 1, drop_last=True)\n",
    "val_loader = DataLoader(val_data, **val_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Architecture definition\n",
    "\n",
    "class MLP(nn.Module):\n",
    "\n",
    "    # define model elements\n",
    "    def __init__(self, size):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        # Sequential model definition: Input -> Linear -> ReLU -> Linear -> Output\n",
    "        \n",
    "        self.model = nn.Sequential(nn.Linear(size[0], size[1]), nn.ReLU(),\n",
    "                                   nn.Linear(size[1], size[2]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        f\n",
    "        # Model forward pass\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "model = MLP([3,128,2])\n",
    "\n",
    "# Define Criterion/ Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define Adam Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "def train_model(train_loader, model):\n",
    "    training_loss = 0\n",
    "    \n",
    "    # Set model in 'Training mode'\n",
    "    model.train()\n",
    "    \n",
    "    # enumerate mini batches\n",
    "    for i, (inputs, targets) in enumerate(train_loader):\n",
    "        \n",
    "        # clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # compute the model output\n",
    "        out = model(inputs)\n",
    "        \n",
    "        # calculate loss\n",
    "        loss = criterion(out, targets)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update model weights\n",
    "        optimizer.step()\n",
    "\n",
    "        training_loss += loss.item()\n",
    "    training_loss /= len(train_loader)\n",
    "    return training_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "\n",
    "def evaluate_model(val_loader, model):\n",
    "    \n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    \n",
    "    # Set model in validation mode\n",
    "    model.eval()\n",
    "    \n",
    "    for i, (inputs, targets) in enumerate(val_loader):\n",
    "        \n",
    "        # evaluate the model on the validation set\n",
    "        out = model(inputs)\n",
    "                \n",
    "        # Calculate validation loss\n",
    "        loss = criterion(out, targets)\n",
    "        \n",
    "        # retrieve numpy array\n",
    "        out = out.detach().numpy()\n",
    "        actual = targets.numpy()\n",
    "\n",
    "        \n",
    "        # convert to class labels\n",
    "        out = np.argmax(out, axis=1)\n",
    "        \n",
    "        # reshape for stacking\n",
    "        actual = actual.reshape((len(actual), 1))\n",
    "        out = out.reshape((len(out), 1))\n",
    "        # store\n",
    "        predictions.append(out)\n",
    "        actuals.append(actual)\n",
    "    \n",
    "    predictions, actuals = np.vstack(predictions), np.vstack(actuals)\n",
    "    # Calculate validation accuracy\n",
    "    acc = accuracy_score(actuals, predictions)\n",
    "    return acc, loss.item()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training loss: 0.8822132185101509, Validation loss:0.5599926710128784, Validation accuracy:60.0%\n",
      "Epoch: 1, Training loss: 0.6252903640270233, Validation loss:0.6960655450820923, Validation accuracy:80.0%\n",
      "Epoch: 2, Training loss: 0.6506033182144165, Validation loss:0.6304447650909424, Validation accuracy:50.0%\n",
      "Epoch: 3, Training loss: 0.6013909876346588, Validation loss:0.3395001292228699, Validation accuracy:80.0%\n",
      "Epoch: 4, Training loss: 0.5528831720352173, Validation loss:0.6480250358581543, Validation accuracy:80.0%\n",
      "Epoch: 5, Training loss: 0.519448147714138, Validation loss:1.041185975074768, Validation accuracy:80.0%\n",
      "Epoch: 6, Training loss: 0.5149343252182007, Validation loss:0.7843772768974304, Validation accuracy:80.0%\n",
      "Epoch: 7, Training loss: 0.5013197004795075, Validation loss:0.2617728114128113, Validation accuracy:80.0%\n",
      "Epoch: 8, Training loss: 0.521775758266449, Validation loss:0.7564153075218201, Validation accuracy:80.0%\n",
      "Epoch: 9, Training loss: 0.488181009888649, Validation loss:0.35054242610931396, Validation accuracy:80.0%\n"
     ]
    }
   ],
   "source": [
    "# Define number of epochs\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    # Train\n",
    "    training_loss = train_model(train_loader, model)\n",
    "\n",
    "    # Validation\n",
    "    val_acc, val_loss = evaluate_model(train_loader, model)\n",
    "    \n",
    "    # Print log of accuracy and loss\n",
    "    print(\"Epoch: \"+str(epoch)+\", Training loss: \"+str(training_loss)+\", Validation loss:\"+str(val_loss)+\n",
    "          \", Validation accuracy:\"+str(val_acc*100)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
